{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGq5j36YR06B2BL7JP7zUF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/6101010/pytorch_image_classification/blob/master/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhjiCqAVXC3r"
      },
      "outputs": [],
      "source": [
        "!pip install -q efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U albumentations\n",
        "# System\n",
        "import cv2\n",
        "import os, os.path\n",
        "from PIL import Image              # from RBG to YCbCr\n",
        "import gc\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# Basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg    # to check images\n",
        "# %matplotlib inline\n",
        "from tqdm.notebook import tqdm      # beautiful progression bar\n",
        "\n",
        "# SKlearn\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import FloatTensor, LongTensor\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Data Augmentation for Image Preprocessing\n",
        "from albumentations import (ToFloat, Normalize, VerticalFlip, HorizontalFlip, Compose, Resize,\n",
        "                            RandomBrightnessContrast, HueSaturationValue, Blur, GaussNoise,\n",
        "                            Rotate, RandomResizedCrop, cutout, ShiftScaleRotate)\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from torchvision.models import resnet34, resnet50\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VynXKZosXMjF",
        "outputId": "3c8683dd-12aa-456b-b8c6-c6530d8f0a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-1.4.24-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.10.3)\n",
            "Collecting albucore==0.0.23 (from albumentations)\n",
            "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.23->albumentations) (3.11.1)\n",
            "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\n",
            "  Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
            "Downloading albumentations-1.4.24-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.23-py3-none-any.whl (14 kB)\n",
            "Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (632 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: simsimd, albucore, albumentations\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.19\n",
            "    Uninstalling albucore-0.0.19:\n",
            "      Successfully uninstalled albucore-0.0.19\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.20\n",
            "    Uninstalling albumentations-1.4.20:\n",
            "      Successfully uninstalled albumentations-1.4.20\n",
            "Successfully installed albucore-0.0.23 albumentations-1.4.24 simsimd-6.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed = 1234):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device available now:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1pGeq0PXps9",
        "outputId": "0ddf8fa5-1a07-42fa-eaaa-68db8775123b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available now: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- STATICS -----\n",
        "output_size = 3\n",
        "# -------------------"
      ],
      "metadata": {
        "id": "ihJyPwB9gx9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5qg_81hhyLQ",
        "outputId": "95364823-a8b8-45dc-8ac7-1b8de975b3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# My Train: with imputed missing values + OHE\n",
        "my_train = pd.read_csv('/content/train.CSV')\n",
        "\n",
        "# OHE\n",
        "to_encode = ['label']\n",
        "encoded_all = []\n",
        "\n",
        "# Merge all\n",
        "train_df = pd.read_csv('train.CSV')\n",
        "\n",
        "# --- Read in Test data (also cleaned, imputed, OHE) ---\n",
        "test_df = pd.read_csv('/content/test.CSV')\n",
        "\n",
        "\n",
        "# Create path column to image folder for both Train and Test\n",
        "path_train = '/content/train'\n",
        "path_test = '/content/test'\n",
        "\n",
        "train_df['path_jpg'] = path_train + train_df['filename'] + '.jpg'\n",
        "test_df['path_jpg'] = path_test + test_df['filename'] + '.jpg'\n",
        "\n",
        "print('Len Train: {:,}'.format(len(train_df)), '\\n' +\n",
        "      'Len Test: {:,}'.format(len(test_df)))\n",
        "\n",
        "# Yay!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yfn5YMYMh7Cj",
        "outputId": "5cba3ec4-22b8-43c3-ecd5-5ac3df8092c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len Train: 389 \n",
            "Len Test: 165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "print(train_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PHnVcvjPr_f",
        "outputId": "14394428-914c-4f00-d44c-2e19d694ba6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          image_path label      filename  \\\n",
            "0  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3817.jpg   \n",
            "1  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3818.jpg   \n",
            "2  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3819.jpg   \n",
            "3  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3820.jpg   \n",
            "4  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3821.jpg   \n",
            "\n",
            "                         path_jpg  \n",
            "0  /content/trainIMG_3817.jpg.jpg  \n",
            "1  /content/trainIMG_3818.jpg.jpg  \n",
            "2  /content/trainIMG_3819.jpg.jpg  \n",
            "3  /content/trainIMG_3820.jpg.jpg  \n",
            "4  /content/trainIMG_3821.jpg.jpg  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 389 entries, 0 to 388\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   image_path  389 non-null    object\n",
            " 1   label       389 non-null    object\n",
            " 2   filename    389 non-null    object\n",
            " 3   path_jpg    389 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 12.3+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_train.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBsvAQp3QpkZ",
        "outputId": "09238597-a8b1-4746-8f99-925cdb4e4aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          image_path label      filename\n",
            "0  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3817.jpg\n",
            "1  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3818.jpg\n",
            "2  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3819.jpg\n",
            "3  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3820.jpg\n",
            "4  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3821.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_train = pd.read_csv('/content/train.CSV')\n",
        "roman_train = pd.read_csv('/content/train.CSV')\n",
        "\n",
        "print(my_train.head())\n",
        "print(roman_train.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtIrd3GnQ6bi",
        "outputId": "075f32f0-ed73-479e-c7e8-d1463f2c3e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          image_path label      filename\n",
            "0  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3817.jpg\n",
            "1  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3818.jpg\n",
            "2  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3819.jpg\n",
            "3  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3820.jpg\n",
            "4  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3821.jpg\n",
            "                                          image_path label      filename\n",
            "0  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3817.jpg\n",
            "1  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3818.jpg\n",
            "2  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3819.jpg\n",
            "3  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3820.jpg\n",
            "4  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3821.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- STATICS -----\n",
        "vertical_flip = 0.5\n",
        "horizontal_flip = 0.5\n",
        "\n",
        "csv_columns = ['label']\n",
        "no_columns = 1\n",
        "# ------------------"
      ],
      "metadata": {
        "id": "z-PS7iQ46-eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'] = train_df['label'].replace({'0': 'low', '1': 'medium', '2': 'high'})\n",
        "\n",
        "train_df['label'] = train_df['label'].astype(str)\n",
        "\n",
        "# 使用 LabelEncoder 进行编码\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n",
        "\n",
        "# 查看编码后的数据\n",
        "print(train_df[['label', 'encoded_label']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea89IWcl8fU3",
        "outputId": "f48ff883-5ed8-4480-e609-533fd88cb908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label  encoded_label\n",
            "0   low              1\n",
            "1   low              1\n",
            "2   low              1\n",
            "3   low              1\n",
            "4   low              1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of csv_data at index=0\n",
        "np.array(train_df.iloc[0][csv_columns].values,dtype=np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "cwXXz4J08V75",
        "outputId": "3a797bc7-10cc-4ef7-dab7-f6ec537e5516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'low'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8e4cc6625bdb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example of csv_data at index=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'low'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from albumentations import Compose, RandomResizedCrop, HorizontalFlip, VerticalFlip, Normalize, HueSaturationValue, RandomBrightnessContrast\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class TeaDataset(Dataset):\n",
        "    def __init__(self, dataframe, vertical_flip=0.5, horizontal_flip=0.5,\n",
        "                 is_train=True, is_valid=False, is_test=False):\n",
        "        self.dataframe, self.is_train, self.is_valid = dataframe, is_train, is_valid\n",
        "        self.vertical_flip, self.horizontal_flip = vertical_flip, horizontal_flip\n",
        "\n",
        "        # Data Augmentation (custom for each dataset type)\n",
        "        if is_train or is_test:\n",
        "            self.transform = Compose([\n",
        "                RandomResizedCrop(height=224, width=224, scale=(0.4, 1.0)),\n",
        "                HorizontalFlip(p=self.horizontal_flip),\n",
        "                VerticalFlip(p=self.vertical_flip),\n",
        "                HueSaturationValue(sat_shift_limit=[0.7, 1.3], hue_shift_limit=[-0.1, 0.1]),\n",
        "                RandomBrightnessContrast(brightness_limit=[0.7, 1.3], contrast_limit=[0.7, 1.3]),\n",
        "                Normalize(),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = Compose([\n",
        "                Normalize(),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # 获取图像路径并读取图像\n",
        "        image_path = self.dataframe['image_path'][index]\n",
        "\n",
        "        # 检查图像路径是否存在\n",
        "        if not cv2.os.path.exists(image_path):\n",
        "            print(f\"Warning: Image path {image_path} not found!\")\n",
        "            return None\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Error: Failed to read image at {image_path}\")\n",
        "            return None\n",
        "\n",
        "        # 获取图像的csv数据\n",
        "        csv_data = np.array(self.dataframe.iloc[index][['label']].values, dtype=np.float32)\n",
        "\n",
        "        # 应用数据增强转换\n",
        "        image = self.transform(image=image)\n",
        "        # 从字典中提取图像\n",
        "        image = image['image']\n",
        "\n",
        "        # 如果是训练集或验证集，返回图像和标签\n",
        "        if self.is_train or self.is_valid:\n",
        "            return (image, csv_data), self.dataframe['label'][index]\n",
        "        else:\n",
        "            # 如果是测试集，仅返回图像和csv数据\n",
        "            return (image, csv_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "DAuvCCjhC71Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MelanomaDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, vertical_flip, horizontal_flip,\n",
        "                 is_train=True, is_valid=False, is_test=False):\n",
        "        self.dataframe, self.is_train, self.is_valid = dataframe, is_train, is_valid\n",
        "        self.vertical_flip, self.horizontal_flip = vertical_flip, horizontal_flip\n",
        "\n",
        "        # Data Augmentation (custom for each dataset type)\n",
        "        if is_train or is_test:\n",
        "            self.transform = Compose([RandomResizedCrop(height=224, width=224, scale=(0.4, 1.0)),\n",
        "                                      ShiftScaleRotate(rotate_limit=90, scale_limit = [0.8, 1.2]),\n",
        "                                      HorizontalFlip(p = self.horizontal_flip),\n",
        "                                      VerticalFlip(p = self.vertical_flip),\n",
        "                                      HueSaturationValue(sat_shift_limit=[0.7, 1.3],\n",
        "                                                         hue_shift_limit=[-0.1, 0.1]),\n",
        "                                      RandomBrightnessContrast(brightness_limit=[0.7, 1.3],\n",
        "                                                               contrast_limit= [0.7, 1.3]),\n",
        "                                      Normalize(),\n",
        "                                      ToTensor()])\n",
        "        else:\n",
        "            self.transform = Compose([Normalize(),\n",
        "                                      ToTensor()])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Select path and read image\n",
        "        image_path = self.dataframe['path_jpg'][index]\n",
        "        image = cv2.imread(image_path)\n",
        "        # For this image also import .csv information (sex, age, anatomy)\n",
        "        csv_data = np.array(self.dataframe.iloc[index][['label']].values,\n",
        "                            dtype=np.float32)\n",
        "\n",
        "        # Apply transforms\n",
        "        image = self.transform(image=image)\n",
        "        # Extract image from dictionary\n",
        "        image = image['image']\n",
        "\n",
        "        # If train/valid: image + class | If test: only image\n",
        "        if self.is_train or self.is_valid:\n",
        "            return (image, csv_data), self.dataframe['target'][index]\n",
        "        else:\n",
        "            return (image, csv_data)"
      ],
      "metadata": {
        "id": "6ohN8MBZBSuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet50Network(nn.Module):\n",
        "    def __init__(self, output_size, no_columns):\n",
        "        super().__init__()\n",
        "        self.no_columns, self.output_size = no_columns, output_size\n",
        "\n",
        "        # Define Feature part (IMAGE)\n",
        "        self.features = resnet50(pretrained=True) # 1000 neurons out\n",
        "        # (CSV data)\n",
        "        self.csv = nn.Sequential(nn.Linear(self.no_columns, 500),\n",
        "                                 nn.BatchNorm1d(500),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(p=0.2))\n",
        "\n",
        "        # Define Classification part\n",
        "        self.classification = nn.Linear(1000 + 500, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, image, csv_data, prints=False):\n",
        "\n",
        "        if prints: print('Input Image shape:', image.shape, '\\n'+\n",
        "                         'Input csv_data shape:', csv_data.shape)\n",
        "\n",
        "        # Image CNN\n",
        "        image = self.features(image)\n",
        "        if prints: print('Features Image shape:', image.shape)\n",
        "\n",
        "        # CSV FNN\n",
        "        csv_data = self.csv(csv_data)\n",
        "        if prints: print('CSV Data:', csv_data.shape)\n",
        "\n",
        "        # Concatenate layers from image with layers from csv_data\n",
        "        image_csv_data = torch.cat((image, csv_data), dim=1)\n",
        "\n",
        "        # CLASSIF\n",
        "        out = self.classification(image_csv_data)\n",
        "        if prints: print('Out shape:', out.shape)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "5i_2D0gaCro5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_example = ResNet50Network(output_size=output_size, no_columns=no_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrDxfbSACuYq",
        "outputId": "c13dec74-b654-4ecc-dbd2-87e21f06738d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 94.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNetwork(nn.Module):\n",
        "    def __init__(self, output_size, no_columns, b4=False, b2=False):\n",
        "        super().__init__()\n",
        "        self.b4, self.b2, self.no_columns = b4, b2, no_columns\n",
        "\n",
        "        # Define Feature part (IMAGE)\n",
        "        if b4:\n",
        "            self.features = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "        elif b2:\n",
        "            self.features = EfficientNet.from_pretrained('efficientnet-b2')\n",
        "        else:\n",
        "            self.features = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "\n",
        "        # (CSV)\n",
        "        self.csv = nn.Sequential(nn.Linear(self.no_columns, 250),\n",
        "                                 nn.BatchNorm1d(250),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(p=0.2),\n",
        "\n",
        "                                 nn.Linear(250, 250),\n",
        "                                 nn.BatchNorm1d(250),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(p=0.2))\n",
        "\n",
        "        # Define Classification part\n",
        "        if b4:\n",
        "            self.classification = nn.Sequential(nn.Linear(1792 + 250, output_size))\n",
        "        elif b2:\n",
        "            self.classification = nn.Sequential(nn.Linear(1408 + 250, output_size))\n",
        "        else:\n",
        "            self.classification = nn.Sequential(nn.Linear(2560 + 250, output_size))\n",
        "\n",
        "\n",
        "    def forward(self, image, csv_data, prints=False):\n",
        "\n",
        "        if prints: print('Input Image shape:', image.shape, '\\n'+\n",
        "                         'Input csv_data shape:', csv_data.shape)\n",
        "\n",
        "        # IMAGE CNN\n",
        "        image = self.features.extract_features(image)\n",
        "        if prints: print('Features Image shape:', image.shape)\n",
        "\n",
        "        if self.b4:\n",
        "            image = F.avg_pool2d(image, image.size()[2:]).reshape(-1, 1792)\n",
        "        elif self.b2:\n",
        "            image = F.avg_pool2d(image, image.size()[2:]).reshape(-1, 1408)\n",
        "        else:\n",
        "            image = F.avg_pool2d(image, image.size()[2:]).reshape(-1, 2560)\n",
        "        if prints: print('Image Reshaped shape:', image.shape)\n",
        "\n",
        "        # CSV FNN\n",
        "        csv_data = self.csv(csv_data)\n",
        "        if prints: print('CSV Data:', csv_data.shape)\n",
        "\n",
        "        # Concatenate\n",
        "        image_csv_data = torch.cat((image, csv_data), dim=1)\n",
        "\n",
        "        # CLASSIF\n",
        "        out = self.classification(image_csv_data)\n",
        "        if prints: print('Out shape:', out.shape)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "HQkLQXXwDgPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an example model - Effnet\n",
        "model_example = EfficientNetwork(output_size=output_size, no_columns=no_columns,\n",
        "                                 b4=False, b2=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y14PlOmQEXrr",
        "outputId": "280d6b36-b753-4e23-9b36-329f53ef86a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b2-8bb594d6.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b2-8bb594d6.pth\n",
            "100%|██████████| 35.1M/35.1M [00:00<00:00, 210MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- STATICS -----\n",
        "train_len = len(train_df)\n",
        "test_len = len(test_df)\n",
        "# -------------------\n",
        "\n",
        "\n",
        "# Out of Fold Predictions\n",
        "oof = np.zeros(shape = (train_len, 1))\n",
        "\n",
        "# Predictions\n",
        "preds_submission = torch.zeros(size = (test_len, 1), dtype=torch.float32, device=device)\n",
        "\n",
        "print('oof shape:', oof.shape, '\\n' +\n",
        "      'predictions shape:', preds_submission.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBa_QV2SEcQT",
        "outputId": "e1961492-d30a-4c3c-bd2e-bb427598f442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oof shape: (389, 1) \n",
            "predictions shape: torch.Size([165, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- STATICS -----\n",
        "k = 6              # number of folds in Group K Fold\n",
        "# ------------------"
      ],
      "metadata": {
        "id": "uDXBSh1FEh_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Object\n",
        "group_fold = GroupKFold(n_splits = k)\n",
        "\n",
        "# Generate indices to split data into training and test set.\n",
        "folds = group_fold.split(X = np.zeros(train_len),\n",
        "                         y = train_df['label'],\n",
        "                         groups = train_df['filename'].tolist())"
      ],
      "metadata": {
        "id": "YXRBGSI7Eo7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- STATICS -----\n",
        "epochs = 15\n",
        "patience = 3\n",
        "TTA = 3\n",
        "num_workers = 8\n",
        "learning_rate = 0.0005\n",
        "weight_decay = 0.0\n",
        "lr_patience = 1            # 1 model not improving until lr is decreasing\n",
        "lr_factor = 0.4            # by how much the lr is decreasing\n",
        "\n",
        "batch_size1 = 32\n",
        "batch_size2 = 16\n",
        "\n",
        "version = 'v6'             # to keep tabs on versions\n",
        "# -------------------"
      ],
      "metadata": {
        "id": "QP3XtoyhFQbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_folds(preds_submission, model, version='v1'):\n",
        "    f = open(f\"logs_{version}.txt\", \"w+\")\n",
        "\n",
        "    for fold, (train_index, valid_index) in enumerate(folds):\n",
        "        with open(f\"logs_{version}.txt\", 'a+') as f:\n",
        "            print('-'*10, 'Fold:', fold+1, '-'*10, file=f)\n",
        "        print('-'*10, 'Fold:', fold+1, '-'*10)\n",
        "\n",
        "        # --- Create Instances ---\n",
        "        best_roc = None\n",
        "        patience_f = patience\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "        scheduler = ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=lr_patience, verbose=True, factor=lr_factor)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # --- Read in Data ---\n",
        "        train_data = train_df.iloc[train_index].reset_index(drop=True)\n",
        "        valid_data = train_df.iloc[valid_index].reset_index(drop=True)\n",
        "\n",
        "        train = TeaLeafDataset(train_data, vertical_flip=vertical_flip, horizontal_flip=horizontal_flip, is_train=True)\n",
        "        valid = TeaLeafDataset(valid_data, vertical_flip=vertical_flip, horizontal_flip=horizontal_flip, is_train=False)\n",
        "\n",
        "        train_loader = DataLoader(train, batch_size=batch_size1, shuffle=True, num_workers=num_workers)\n",
        "        valid_loader = DataLoader(valid, batch_size=batch_size2, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            start_time = time.time()\n",
        "            correct = 0\n",
        "            train_losses = 0\n",
        "\n",
        "            model.train()\n",
        "            for (images, csv_data), labels in train_loader:\n",
        "                images = torch.tensor(images, device=device, dtype=torch.float32)\n",
        "                csv_data = torch.tensor(csv_data, device=device, dtype=torch.float32)\n",
        "                labels = torch.tensor(labels, device=device, dtype=torch.long)\n",
        "                optimizer.zero_grad()\n",
        "                out = model(images, csv_data)\n",
        "                loss = criterion(out, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_losses += loss.item()\n",
        "                train_preds = torch.argmax(out, dim=1)\n",
        "                correct += (train_preds == labels).sum().item()\n",
        "\n",
        "            train_acc = correct / len(train_index)\n",
        "\n",
        "            model.eval()\n",
        "            valid_preds = torch.zeros(size=(len(valid_index), 1), device=device, dtype=torch.float32)\n",
        "            with torch.no_grad():\n",
        "                for k, ((images, csv_data), labels) in enumerate(valid_loader):\n",
        "                    images = torch.tensor(images, device=device, dtype=torch.float32)\n",
        "                    csv_data = torch.tensor(csv_data, device=device, dtype=torch.float32)\n",
        "                    labels = torch.tensor(labels, device=device, dtype=torch.long)\n",
        "\n",
        "                    out = model(images, csv_data)\n",
        "                    valid_preds[k * images.shape[0]: k * images.shape[0] + images.shape[0]] = out\n",
        "\n",
        "                valid_acc = accuracy_score(valid_data['target'].values, torch.argmax(valid_preds.cpu(), dim=1))\n",
        "                valid_roc = roc_auc_score(valid_data['target'].values, valid_preds.cpu())\n",
        "\n",
        "                duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
        "\n",
        "                with open(f\"logs_{version}.txt\", 'a+') as f:\n",
        "                    print('{} | Epoch: {}/{} | Loss: {:.4} | Train Acc: {:.3} | Valid Acc: {:.3} | ROC: {:.3}'.format(\n",
        "                        duration, epoch + 1, epochs, train_losses, train_acc, valid_acc, valid_roc), file=f)\n",
        "\n",
        "                print('{} | Epoch: {}/{} | Loss: {:.4} | Train Acc: {:.3} | Valid Acc: {:.3} | ROC: {:.3}'.format(\n",
        "                    duration, epoch + 1, epochs, train_losses, train_acc, valid_acc, valid_roc))\n",
        "\n",
        "                scheduler.step(valid_roc)\n",
        "\n",
        "                if not best_roc:\n",
        "                    best_roc = valid_roc\n",
        "                    torch.save(model.state_dict(), f\"Fold{fold+1}_Epoch{epoch+1}_ValidAcc_{valid_acc:.3f}_ROC_{valid_roc:.3f}.pth\")\n",
        "                    continue\n",
        "\n",
        "                if valid_roc > best_roc:\n",
        "                    best_roc = valid_roc\n",
        "                    patience_f = patience\n",
        "                    torch.save(model.state_dict(), f\"Fold{fold+1}_Epoch{epoch+1}_ValidAcc_{valid_acc:.3f}_ROC_{valid_roc:.3f}.pth\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0BQ0F6ejG6Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the logs during training\n",
        "f = open('../input/siim-melanoma-prep-data/logs_v7.txt', \"r\")\n",
        "contents = f.read()\n",
        "print(contents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "-QO_inO4HOAy",
        "outputId": "f5ad04df-4539-44a3-baec-e8d44c3b6ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../input/siim-melanoma-prep-data/logs_v7.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-f066b3a181a3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the logs during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/siim-melanoma-prep-data/logs_v7.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/siim-melanoma-prep-data/logs_v7.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import OOF (pretrained)\n",
        "oof = pd.read_csv('../content/oof_v7.CSV')\n",
        "\n",
        "# ROC on full Training data\n",
        "print('OOF ROC: {:.3f}'.format(roc_auc_score(train_df['target'], oof)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "GOm4JnrNHljE",
        "outputId": "375b73ac-f4d8-45d0-d1c0-ee784199cd53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EmptyDataError",
          "evalue": "No columns to parse from file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-41f8e3b37f0f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import OOF (pretrained)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../content/oof_v7.CSV'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ROC on full Training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OOF ROC: {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 手动映射标签（根据你希望的顺序）\n",
        "label_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
        "\n",
        "# 使用 map 函数将 'label' 转换为对应的数字\n",
        "train_df['encoded_label'] = train_df['label'].map(label_mapping)\n",
        "\n",
        "# 打印映射后的结果\n",
        "print(train_df[['label', 'encoded_label']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dDnvsYJWNBF",
        "outputId": "8a0ac564-0a6e-41d5-cb61-60734145574e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label  encoded_label\n",
            "0   low              0\n",
            "1   low              0\n",
            "2   low              0\n",
            "3   low              0\n",
            "4   low              0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oof = np.zeros(shape=(len(train_df),))\n",
        "oof = np.random.choice([0, 1, 2], size=len(train_df))\n"
      ],
      "metadata": {
        "id": "6BHlnfKXYCsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "train_df['encoded_label'] = train_df['label'].map(label_map)\n",
        "\n",
        "# 调用 confusion_matrix\n",
        "cf_matrix = confusion_matrix(train_df['encoded_label'], oof)\n"
      ],
      "metadata": {
        "id": "13N4Dk6_YFbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 将 'low', 'medium', 'high' 转换为 0, 1, 2\n",
        "label_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "train_df['encoded_label'] = train_df['label'].map(label_map)\n"
      ],
      "metadata": {
        "id": "sKJNgbgpYUtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib\n",
        "\n",
        "oof[oof == 0] = 0\n",
        "\n",
        "oof[oof == 0] = 0  # Low quality\n",
        "oof[oof == 1] = 1  # Medium quality\n",
        "oof[oof == 2] = 2  # High quality\n",
        "\n",
        "# Create Confusion Matrix for 3-class classification\n",
        "cf_matrix = confusion_matrix(train_df['label'], oof)\n",
        "\n",
        "# Pretty CM:\n",
        "group_names = ['True Low', 'False Medium', 'False High', 'True Medium', 'False Low', 'True High', 'False Low', 'False Medium', 'True High']\n",
        "# Format of the absolute numbers\n",
        "group_counts = ['{:,}'.format(value) for value in cf_matrix.flatten()]\n",
        "# Format for relative numbers\n",
        "group_percentages = ['{0:.1%}'.format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "\n",
        "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
        "labels = np.asarray(labels).reshape(3, 3)\n",
        "\n",
        "# --- The figure ---\n",
        "plt.figure(figsize=(16, 5))\n",
        "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Oranges', xticklabels=['Low', 'Medium', 'High'],\n",
        "            yticklabels=['Low', 'Medium', 'High'], cbar=False)\n",
        "\n",
        "matplotlib.rcParams.update({'font.size': 15})\n",
        "plt.tick_params(axis='both', labelsize=15)\n",
        "plt.title('Confusion Matrix: Tea Leaf Classification', fontsize=20)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GnY3V2ivHn42",
        "outputId": "cf28b1ac-2c3b-4d90-fec8-2af14afb27f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mix of label input types (string and number)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-09b299acbd10>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Create Confusion Matrix for 3-class classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Pretty CM:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df['label']))\n",
        "print(oof.shape)\n",
        "\n",
        "train_df = train_df.dropna(subset=['label'])\n",
        "\n",
        "train_df['label'] = train_df['label'].astype(int)\n",
        "oof = oof.astype(int)\n",
        "\n",
        "# 生成混淆矩阵\n",
        "cf_matrix = confusion_matrix(train_df['label'], oof)\n",
        "\n",
        "# 输出混淆矩阵\n",
        "print(cf_matrix)\n",
        "\n",
        "# 可视化混淆矩阵\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'],\n",
        "            yticklabels=['Class 0', 'Class 1', 'Class 2'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "JcVNQ9VJJUQb",
        "outputId": "958b96e9-c9c9-47ad-d60b-f42fd953a6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "389\n",
            "(0,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: 'low'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-144839455f4f>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 确保数据是正确的类型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0moof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6641\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6642\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6643\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6644\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_astype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'low'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看 train_df 的前几行，确保数据被正确加载\n",
        "print(train_df.head())\n",
        "\n",
        "# 检查 train_df['label'] 是否为空\n",
        "print(train_df['label'].isna().sum())  # 如果返回大于0，说明有缺失值\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jsmJObOJqt_",
        "outputId": "7614eb9c-e97a-4223-ec9c-e44cfc496f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          image_path label      filename  \\\n",
            "0  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3817.jpg   \n",
            "1  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3818.jpg   \n",
            "2  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3819.jpg   \n",
            "3  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3820.jpg   \n",
            "4  D:\\HuaweiMoveData\\Users\\35045\\Desktop\\train_te...   low  IMG_3821.jpg   \n",
            "\n",
            "                         path_jpg  encoded_label  \n",
            "0  /content/trainIMG_3817.jpg.jpg              0  \n",
            "1  /content/trainIMG_3818.jpg.jpg              0  \n",
            "2  /content/trainIMG_3819.jpg.jpg              0  \n",
            "3  /content/trainIMG_3820.jpg.jpg              0  \n",
            "4  /content/trainIMG_3821.jpg.jpg              0  \n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看列名\n",
        "print(train_df.columns)\n",
        "\n",
        "# 确保列名是 'label'\n",
        "if 'label' not in train_df.columns:\n",
        "    print(\"Label column is missing or has a different name!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_wnZLMTJtLR",
        "outputId": "68ee8c63-e487-47ad-df27-bdeb47c68d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['image_path', 'label', 'filename', 'path_jpg', 'encoded_label'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 检查 train_df['label'] 的长度\n",
        "print(len(train_df['label']))\n",
        "\n",
        "# 检查 oof 的长度\n",
        "print(oof.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK-h9q6JJugV",
        "outputId": "9880708e-66f6-4541-c7e6-c763294bb13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "389\n",
            "(389,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#模拟了一些数据\n",
        "oof = np.random.choice([0, 1, 2], size=len(train_df))\n",
        "print(oof.dtype)\n",
        "print(oof.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySriLG2AYsrl",
        "outputId": "ed7ed289-3e93-43a2-d3da-9d183c73cd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n",
            "(389,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 计算混淆矩阵\n",
        "cf_matrix = confusion_matrix(train_df['encoded_label'], oof)\n",
        "\n",
        "# 输出混淆矩阵\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5kVPyjXJJ09",
        "outputId": "44cccda9-b66b-4465-a1b5-171b8933da6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[32 39 41]\n",
            " [49 46 49]\n",
            " [37 54 42]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 打印分类报告\n",
        "report = classification_report(train_df['encoded_label'], oof, target_names=[\"low\", \"medium\", \"high\"])\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhx6dAdbY0kp",
        "outputId": "d70b9f9f-a20a-4d5c-f3d6-be6f5bf37473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         low       0.27      0.29      0.28       112\n",
            "      medium       0.33      0.32      0.33       144\n",
            "        high       0.32      0.32      0.32       133\n",
            "\n",
            "    accuracy                           0.31       389\n",
            "   macro avg       0.31      0.31      0.31       389\n",
            "weighted avg       0.31      0.31      0.31       389\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 绘制热力图\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"low\", \"medium\", \"high\"], yticklabels=[\"low\", \"medium\", \"high\"])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "_lNGt5ZnY1mC",
        "outputId": "198930ba-e32b-48b4-820c-785a163a9a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}